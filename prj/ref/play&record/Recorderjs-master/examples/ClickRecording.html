<!DOCTYPE html>

<html>
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
	<title>Live input record and playback</title>
  <style>
    body {
      background-color: black;
      margin: 0;
    }
    canvas {
      width: 100%;
      height: 100%
    }
  </style>
  <style type='text/css'>
    ul { list-style: none; }
    #recordingslist audio { display: block; margin-bottom: 10px; }
  </style>
</head>
<body>
  
  <ul id="recordingslist"></ul>
  <script src="../../../../lib/three.js"></script>
  <script src="../../../../lib/recorder.js"></script>
  <script src="../../../../lib/jquery.js"></script>
  <script>
    /***
  function console.log(e, data) {
    log.innerHTML += "\n" + e + " " + (data || '');
  }
***/
  const scene = new THREE.Scene();
  const camera = new THREE.PerspectiveCamera( 75, window.innerWidth / window.innerHeight, 0.1, 1000 );

  const renderer = new THREE.WebGLRenderer({alpha:true});
  renderer.setSize( window.innerWidth, window.innerHeight );
  document.body.appendChild( renderer.domElement );
  
  const LightSphere = new THREE.SphereGeometry( 0.5, 16, 8 );
  PointLight = new THREE.PointLight( 0xffffff, 1000000000, 0 );
  PointLight.add( new THREE.Mesh( LightSphere, new THREE.MeshBasicMaterial( { color: 0x0 } ) ) );
  PointLight.visible = true;
  PointLight.position.z = -100;
  scene.add( PointLight );

  var bubbles = [];
  var PlayState = 0;

  var raycaster = new THREE.Raycaster();
  var mouse = new THREE.Vector2();
  var audio_context;
  var recorder;

  init();
  CreateBubble();
	animate();

  window.addEventListener('click', onMouseClick, false);

  function startUserMedia(stream) {
    var input = audio_context.createMediaStreamSource(stream);
    console.log('Media stream created.');

    // Uncomment if you want the audio to feedback directly
    //input.connect(audio_context.destination);
    //console.log('Input connected to audio context destination.');
    
    recorder = new Recorder(input);
    console.log('Recorder initialised.');
  }

  function startRecording() {
    recorder && recorder.record();
    console.log('Recording...');
  }

  function stopRecording() {
    recorder && recorder.stop();
    console.log('Stopped recording.');
    
    // create WAV download link using audio data blob
    //createDownloadLink();
    createLocalFile();
    
    recorder.clear();
  }

  function createDownloadLink() {
    recorder && recorder.exportWAV(function(blob) {
      var url = URL.createObjectURL(blob);
      var li = document.createElement('li');
      var au = document.createElement('audio');
      var hf = document.createElement('a');
      
      au.controls = true;
      au.src = url;
      hf.href = url;
      hf.download = new Date().toISOString() + '.wav';
      hf.innerHTML = hf.download;
      li.appendChild(au);
      li.appendChild(hf);
      recordingslist.appendChild(li);
      //scene.add(li)
    });
  }

  function createLocalFile() {
    recorder && recorder.exportWAV(function (blob) {
				console.log(blob);
        /***
				var formdata = new FormData(); // form 表单 {key:value}
				formdata.append("audio", blob); // form input type="file"
				$.ajax({
					url: "/receive_audio",
					type: 'get',
					processData: false,
					contentType: false,
					data: formdata,
					dataType: 'json',
					success: function (data) {
					console.log(data);
					document.getElementById("player").src = "./" + data.filename;
					}
				})
        ***/
        var urlObject = window.URL || window.webkitURL || window;

        var downloadData = blob;
        var name = "gua.wav"
        var save_link = document.createElementNS("http://www.w3.org/1999/xhtml", "a")
        save_link.href = urlObject.createObjectURL(downloadData);
        save_link.download = name;
		});
  }

  function init() {
    try {
      // webkit shim
      window.AudioContext = window.AudioContext || window.webkitAudioContext;
      navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia;
      window.URL = window.URL || window.webkitURL;
      
      audio_context = new AudioContext;
      console.log('Audio context set up.');
      console.log('navigator.getUserMedia ' + (navigator.getUserMedia ? 'available.' : 'not present!'));
    } catch (e) {
      alert('No web audio support in this browser!');
    }
    
    navigator.getUserMedia({audio: true}, startUserMedia, function(e) {
      console.log('No live audio input: ' + e);
    });
  };

  function onMouseClick(event) {
				//通过鼠标点击的位置计算出raycaster所需要的点的位置，以屏幕中心为原点，值的范围为-1到1.

				mouse.x = (event.clientX / window.innerWidth) * 2 - 1;
				mouse.y = - (event.clientY / window.innerHeight) * 2 + 1;

				// 通过鼠标点的位置和当前相机的矩阵计算出raycaster
				raycaster.setFromCamera(mouse, camera);

				// 获取raycaster直线和所有模型相交的数组集合
				var intersects = raycaster.intersectObjects(scene.children);

				console.log(intersects);

				//将所有的相交的模型的颜色设置为红色，如果只需要将第一个触发事件，那就数组的第一个模型改变颜色即可
				if (!intersects.length) {
					return;
				}
				if (PlayState==0) {
					PlayState = 1;
					var obj = intersects[0].object;
					var tmpPosX = obj.position.x;
					var tmpPosY = obj.position.y;
					var tmpPosZ = obj.position.z;
					scene.remove(obj);
					//console.log(obj);
          var NewMaterial = new THREE.MeshBasicMaterial( {color:0xffffff} );
          //NewMaterial.map = res;
          obj = new THREE.Mesh(obj.geometry, NewMaterial);
          //console.log(tmpPos);
          obj.position.x = tmpPosX;
          obj.position.y = tmpPosY;
          obj.position.z = tmpPosZ;
          console.log(obj.position);
          bubbles.pop();
          bubbles.push( obj );
          scene.add( obj );
					
					//AudioPlay();
					//StartRecord();
					startRecording();
				}
				else if (PlayState==1) {
					PlayState = 0;
					//StopRecord();
					stopRecording();
				}
			}

			function CreateBubble() {
				var geometry = new THREE.SphereGeometry(1,30,30);
				var material = new THREE.MeshBasicMaterial({color:0xff0000});
				bubble = new THREE.Mesh( geometry, material );
				scene.add( bubble );

				bubble.position.x = 2;
				bubble.position.y = 0;

				bubbles.push(bubble);

				camera.position.z = 5;
			}

			function animate() {
				requestAnimationFrame( animate );

				for ( let i = 0; i < bubbles.length; i ++ ) {

					const bubble = bubbles[ i ];
					bubble.rotation.x += 0.01;
					bubble.rotation.y += 0.01;
					bubble.rotation.z += 0.01;
					}

				renderer.render( scene, camera );
			};
  </script>

  <script src="../dist/recorder.js"></script>
</body>
</html>
